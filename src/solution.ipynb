{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression: Banking Marketing Campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle imports upfront\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 1.1. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url='https://raw.githubusercontent.com/4GeeksAcademy/logistic-regression-project-tutorial/main/bank-marketing-campaign-data.csv'\n",
    "data_df=pd.read_csv(data_url, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the test-train split\n",
    "training_df, testing_df=train_test_split(\n",
    "    data_df,\n",
    "    test_size=0.25, \n",
    "    random_state=315\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n",
    "\n",
    "### 2.1. Baseline model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many yes/no labels do we have\n",
    "training_df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy for constant 'no' model\n",
    "accuracy=(training_df['y'].value_counts()['no']/len(training_df['y']))*100\n",
    "print(f'Accuracy of constant \"no\" model: {accuracy:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy of random 50:50 guess\n",
    "labels=['yes', 'no']\n",
    "choices=random.choices(labels, k=len(training_df['y']))\n",
    "accuracy=accuracy_score(training_df['y'], choices)\n",
    "print(f'Accuracy of random guesses: {accuracy*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data composition & cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=['y','job','education','marital','default','housing','loan','contact','poutcome','day_of_week','month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs=plt.subplots(4,3, figsize=(12,10))\n",
    "axs=axs.flatten()\n",
    "\n",
    "fig.suptitle('Customer feature level counts')\n",
    "\n",
    "for i, feature in enumerate(categorical_features):\n",
    "\n",
    "    # Plot neighborhood group level counts\n",
    "    level_counts=training_df[feature].value_counts()\n",
    "\n",
    "    axs[i].set_title(feature)\n",
    "    axs[i].bar(list(range(len(level_counts))), level_counts, tick_label=level_counts.index, color='black')\n",
    "    axs[i].tick_params(axis='x', labelrotation=45)\n",
    "    axs[i].set_ylabel('Customers')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features=['age','duration','campaign','pdays','previous','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs=plt.subplots(4,3, figsize=(12,10))\n",
    "axs=axs.flatten()\n",
    "\n",
    "fig.suptitle('Customer feature distributions')\n",
    "\n",
    "for i, feature in enumerate(numerical_features):\n",
    "\n",
    "    axs[i].set_title(feature)\n",
    "    axs[i].hist(training_df[feature], color='black')\n",
    "    axs[i].tick_params(axis='x', labelrotation=45)\n",
    "    axs[i].set_ylabel('Customers')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Feature interactions & selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=['job','marital','default','housing','loan','contact','poutcome','day_of_week','month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs=plt.subplots(3,3, figsize=(12,10))\n",
    "axs=axs.flatten()\n",
    "\n",
    "fig.suptitle('Customer responses by feature level')\n",
    "\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    groups=training_df.groupby([feature, 'y']).size()\n",
    "    groups_df=groups.reset_index()\n",
    "    groups_df.rename({0: 'Customers'}, axis=1, inplace=True)\n",
    "\n",
    "    axs[i].set_title(f'{feature}')\n",
    "    sns.barplot(groups_df, x=feature, y='Customers', hue='y', ax=axs[i])\n",
    "    axs[i].tick_params(axis='x', labelrotation=45)\n",
    "    axs[i].set_ylabel('Customers')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features=['age','duration','campaign','pdays','previous','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs=plt.subplots(4,3, figsize=(12,10))\n",
    "axs=axs.flatten()\n",
    "\n",
    "fig.suptitle('Comparison of neighborhood group and interval variables')\n",
    "\n",
    "for i, feature in enumerate(numerical_features):\n",
    "\n",
    "    plot_df=training_df[training_df[feature] != 0]\n",
    "\n",
    "    if stats.kurtosis(plot_df[feature].dropna()) > 20:\n",
    "        log_scale=True\n",
    "    else:\n",
    "        log_scale=False\n",
    "\n",
    "    sns.boxplot(training_df, x='y', y=feature, log_scale=log_scale, ax=axs[i])\n",
    "    axs[i].tick_params(axis='x', labelrotation=45)\n",
    "    axs[i].set_xlabel('')\n",
    "    axs[i].set_ylabel(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_drops=['pdays']\n",
    "training_df.drop(feature_drops, axis=1, inplace=True)\n",
    "testing_df.drop(feature_drops, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Feature encoding & scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=['job','marital','default','housing','loan','contact','poutcome']\n",
    "\n",
    "encoder=OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoder.fit(training_df[categorical_features])\n",
    "encoded_training_features=encoder.transform(training_df[categorical_features])\n",
    "encoded_testing_features=encoder.transform(testing_df[categorical_features])\n",
    "\n",
    "encoded_training_features_df=pd.DataFrame(\n",
    "    encoded_training_features,\n",
    "    columns=encoder.get_feature_names_out()\n",
    ")\n",
    "\n",
    "encoded_testing_features_df=pd.DataFrame(\n",
    "    encoded_testing_features,\n",
    "    columns=encoder.get_feature_names_out()\n",
    ")\n",
    "\n",
    "encoded_training_features_df.head().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features=['age','duration','campaign','previous','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']\n",
    "\n",
    "standard_scaler=StandardScaler().fit(training_df[numerical_features])\n",
    "scaled_training_features=standard_scaler.transform(training_df[numerical_features])\n",
    "scaled_testing_features=standard_scaler.transform(testing_df[numerical_features])\n",
    "\n",
    "scaled_training_features_df=pd.DataFrame(\n",
    "    scaled_training_features,\n",
    "    columns=numerical_features\n",
    ")\n",
    "\n",
    "scaled_testing_features_df=pd.DataFrame(\n",
    "    scaled_testing_features,\n",
    "    columns=numerical_features\n",
    ")\n",
    "\n",
    "scaled_training_features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_time_features(data_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''Takes a Pandas dataframe and uses cyclical sin/cos to encode\n",
    "    month and day features. Returns updated dataframe.'''\n",
    "\n",
    "    time_df=data_df.copy()\n",
    "\n",
    "    # First convert the features to numeric\n",
    "    dict={'mon' : '1', 'tue' : '2', 'wed': '3', 'thu' : '4', 'fri': '5'}\n",
    "    time_df['day_of_week']=time_df['day_of_week'].replace(dict)\n",
    "\n",
    "    dict={'jan' : '1', 'feb' : '2', 'mar': '3', 'apr' : '4', 'may': '5', 'jun': '6', 'jul': '7', 'aug': '8', 'sep': '9', 'oct': '10', 'nov': '11', 'dec': '12'}\n",
    "    time_df['month']=time_df['month'].replace(dict)\n",
    "\n",
    "    # And fix the dtypes\n",
    "    time_df['day_of_week']=time_df['day_of_week'].astype(float)\n",
    "    time_df['month']=time_df['month'].astype(float)\n",
    "\n",
    "    # Now encode the day and month with sin/cos components\n",
    "    time_df['day_sin']=np.sin(2 * np.pi * time_df['day_of_week']/7.0)\n",
    "    time_df['day_cos']=np.cos(2 * np.pi * time_df['day_of_week']/7.0)\n",
    "\n",
    "    time_df['month_sin']=np.sin(2 * np.pi * time_df['month']/12.0)\n",
    "    time_df['month_cos']=np.cos(2 * np.pi * time_df['month']/12.0)\n",
    "\n",
    "    # Drop the original string features\n",
    "    time_df.drop(['month', 'day_of_week'], axis=1, inplace=True)\n",
    "\n",
    "    return time_df.reset_index(drop=True)\n",
    "\n",
    "training_time_features=encode_time_features(training_df[['day_of_week', 'month']])\n",
    "testing_time_features=encode_time_features(testing_df[['day_of_week', 'month']])\n",
    "\n",
    "training_time_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last, encode the labels\n",
    "label_encoder=LabelEncoder().fit(training_df['y'])\n",
    "training_labels=label_encoder.transform(training_df['y'])\n",
    "testing_labels=label_encoder.transform(testing_df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes back together\n",
    "training_features=pd.concat([encoded_training_features_df, scaled_training_features_df, training_time_features], axis=1)\n",
    "testing_features=pd.concat([encoded_testing_features_df, scaled_testing_features_df, testing_time_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression()\n",
    "model.fit(training_features, training_labels)\n",
    "\n",
    "test_predictions=model.predict(testing_features)\n",
    "test_accuracy=accuracy_score(testing_labels, test_predictions)*100\n",
    "print(f'Test set accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model optimization\n",
    "\n",
    "### 4.1. Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={\n",
    "    'C': [0.125, 0.25, 0.5, 1, 2, 4, 8],\n",
    "    #'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    'fit_intercept': [True, False],\n",
    "    'max_iter': [50, 100, 200]\n",
    "}\n",
    "\n",
    "model=LogisticRegression()\n",
    "grid=GridSearchCV(model, hyperparameters, scoring='accuracy', cv=5)\n",
    "grid.fit(training_features, training_labels)\n",
    "winning_parameters=grid.best_params_\n",
    "print(f'Best hyperparameters: {winning_parameters}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Final model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression(**winning_parameters)\n",
    "model.fit(training_features, training_labels)\n",
    "\n",
    "test_predictions=model.predict(testing_features)\n",
    "test_accuracy=accuracy_score(testing_labels, test_predictions)*100\n",
    "print(f'Test set accuracy: {test_accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
