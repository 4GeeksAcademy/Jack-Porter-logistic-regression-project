{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression: Banking Marketing Campaign\n",
    "\n",
    "This notebook analyzes a banking marketing campaign dataset to predict whether customers will subscribe to a term deposit. We'll build and optimize a logistic regression model to classify customer responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle imports upfront\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as rd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data acquisition\n",
    "\n",
    "We'll start by loading the dataset from the provided URL and saving a local copy for future use.\n",
    "\n",
    "### 1.1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the provided URL\n",
    "data_url = 'https://raw.githubusercontent.com/4GeeksAcademy/logistic-regression-project-tutorial/main/bank-marketing-campaign-data.csv'\n",
    "data_df = pd.read_csv(data_url, sep=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Save local copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory for raw data\n",
    "Path('../data/raw').mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save a local copy of the raw data\n",
    "data_df.to_parquet('../data/raw/bank-marketing-campaign-data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>housemaid</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>admin.</td>\n",
       "      <td>services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital</th>\n",
       "      <td>married</td>\n",
       "      <td>married</td>\n",
       "      <td>married</td>\n",
       "      <td>married</td>\n",
       "      <td>married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>basic.4y</td>\n",
       "      <td>high.school</td>\n",
       "      <td>high.school</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>high.school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact</th>\n",
       "      <td>telephone</td>\n",
       "      <td>telephone</td>\n",
       "      <td>telephone</td>\n",
       "      <td>telephone</td>\n",
       "      <td>telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>may</td>\n",
       "      <td>may</td>\n",
       "      <td>may</td>\n",
       "      <td>may</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week</th>\n",
       "      <td>mon</td>\n",
       "      <td>mon</td>\n",
       "      <td>mon</td>\n",
       "      <td>mon</td>\n",
       "      <td>mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>261</td>\n",
       "      <td>149</td>\n",
       "      <td>226</td>\n",
       "      <td>151</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pdays</th>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poutcome</th>\n",
       "      <td>nonexistent</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>nonexistent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp.var.rate</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cons.price.idx</th>\n",
       "      <td>93.994</td>\n",
       "      <td>93.994</td>\n",
       "      <td>93.994</td>\n",
       "      <td>93.994</td>\n",
       "      <td>93.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <td>-36.4</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>-36.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euribor3m</th>\n",
       "      <td>4.857</td>\n",
       "      <td>4.857</td>\n",
       "      <td>4.857</td>\n",
       "      <td>4.857</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nr.employed</th>\n",
       "      <td>5191.0</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0            1            2            3  \\\n",
       "age                      56           57           37           40   \n",
       "job               housemaid     services     services       admin.   \n",
       "marital             married      married      married      married   \n",
       "education          basic.4y  high.school  high.school     basic.6y   \n",
       "default                  no      unknown           no           no   \n",
       "housing                  no           no          yes           no   \n",
       "loan                     no           no           no           no   \n",
       "contact           telephone    telephone    telephone    telephone   \n",
       "month                   may          may          may          may   \n",
       "day_of_week             mon          mon          mon          mon   \n",
       "duration                261          149          226          151   \n",
       "campaign                  1            1            1            1   \n",
       "pdays                   999          999          999          999   \n",
       "previous                  0            0            0            0   \n",
       "poutcome        nonexistent  nonexistent  nonexistent  nonexistent   \n",
       "emp.var.rate            1.1          1.1          1.1          1.1   \n",
       "cons.price.idx       93.994       93.994       93.994       93.994   \n",
       "cons.conf.idx         -36.4        -36.4        -36.4        -36.4   \n",
       "euribor3m             4.857        4.857        4.857        4.857   \n",
       "nr.employed          5191.0       5191.0       5191.0       5191.0   \n",
       "y                        no           no           no           no   \n",
       "\n",
       "                          4  \n",
       "age                      56  \n",
       "job                services  \n",
       "marital             married  \n",
       "education       high.school  \n",
       "default                  no  \n",
       "housing                  no  \n",
       "loan                    yes  \n",
       "contact           telephone  \n",
       "month                   may  \n",
       "day_of_week             mon  \n",
       "duration                307  \n",
       "campaign                  1  \n",
       "pdays                   999  \n",
       "previous                  0  \n",
       "poutcome        nonexistent  \n",
       "emp.var.rate            1.1  \n",
       "cons.price.idx       93.994  \n",
       "cons.conf.idx         -36.4  \n",
       "euribor3m             4.857  \n",
       "nr.employed          5191.0  \n",
       "y                        no  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation\n",
    "\n",
    "Before training our model, we need to prepare the data by splitting it into training and testing sets, and encoding categorical variables for use with scikit-learn.\n",
    "\n",
    "### 2.1. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (75%) and testing (25%) sets\n",
    "# This ensures we have unseen data to evaluate our final model\n",
    "training_df, test_df = train_test_split(data_df, test_size=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Feature encoding\n",
    "\n",
    "Machine learning algorithms work with numerical data, so we need to convert categorical variables (strings) to numerical format using ordinal encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 41163 entries, 35070 to 32747\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41163 non-null  int64  \n",
      " 1   job             41163 non-null  float64\n",
      " 2   marital         41163 non-null  float64\n",
      " 3   education       41163 non-null  float64\n",
      " 4   default         41163 non-null  float64\n",
      " 5   housing         41163 non-null  float64\n",
      " 6   loan            41163 non-null  float64\n",
      " 7   contact         41163 non-null  float64\n",
      " 8   month           41163 non-null  float64\n",
      " 9   day_of_week     41163 non-null  float64\n",
      " 10  duration        41163 non-null  int64  \n",
      " 11  campaign        41163 non-null  int64  \n",
      " 12  pdays           41163 non-null  int64  \n",
      " 13  previous        41163 non-null  int64  \n",
      " 14  poutcome        41163 non-null  float64\n",
      " 15  emp.var.rate    41163 non-null  float64\n",
      " 16  cons.price.idx  41163 non-null  float64\n",
      " 17  cons.conf.idx   41163 non-null  float64\n",
      " 18  euribor3m       41163 non-null  float64\n",
      " 19  nr.employed     41163 non-null  float64\n",
      " 20  y               41163 non-null  float64\n",
      "dtypes: float64(16), int64(5)\n",
      "memory usage: 6.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Categorical features with 'object' datatypes (string) which need encoding\n",
    "categorical_features = ['y','job','education','marital','default','housing','loan','contact','poutcome','day_of_week','month']\n",
    "\n",
    "# Instantiate a encoder\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# Encode the categorical features in the training and testing datasets\n",
    "training_df[categorical_features] = encoder.fit_transform(training_df[categorical_features])\n",
    "test_df[categorical_features] = encoder.fit_transform(test_df[categorical_features])\n",
    "\n",
    "# Inspect the result - there should be only float or int datatypes left\n",
    "training_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model training\n",
    "\n",
    "We'll establish baseline performance using simple models, then build and optimize a logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty dictionary to store performance results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Random model performance\n",
    "\n",
    "A random classifier serves as our weakest baseline - any useful model should significantly outperform random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random model: 44.00%\n"
     ]
    }
   ],
   "source": [
    "# Generate random predictions for the testing set\n",
    "# This serves as a baseline to compare our model performance against\n",
    "predictions = [random.choice([0, 1]) for _ in range(len(test_df))]\n",
    "# Calculate accuracy of random model\n",
    "accuracy = accuracy_score(test_df['y'], predictions) * 100\n",
    "# Store the accuracy in the results dictionary\n",
    "results['Random'] = accuracy\n",
    "\n",
    "print(f'Accuracy of random model: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Constant 'no' model performance\n",
    "\n",
    "Since this is a classification problem with imbalanced classes, we should check how well a model that always predicts the majority class would perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of constant \"no\" model: 96.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy if we always predict 'no' (the majority class)\n",
    "accuracy = (test_df['y'].value_counts()[0]/len(test_df['y'])) * 100\n",
    "\n",
    "# Store the accuracy in the results dictionary\n",
    "results['Constant No'] = accuracy\n",
    "\n",
    "print(f'Accuracy of constant \"no\" model: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Logistic regression model performance\n",
    "\n",
    "Now we'll train a basic logistic regression model with default parameters to see how much improvement we get over the baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a basic logistic regression model with default parameters\n",
    "\n",
    "# Make predictions on the testing set\n",
    "\n",
    "# Calculate accuracy of the test set predictions\n",
    "\n",
    "# Store the accuracy in the results dictionary\n",
    "results['Regression'] = accuracy\n",
    "\n",
    "print(f\"Testing accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Optimized logistic regression model performance\n",
    "\n",
    "To get the best performance, we'll use grid search with cross-validation to find the optimal hyperparameters for our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters to search over\n",
    "# These parameters can significantly affect model performance\n",
    "hyperparameters = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],  # Different optimization algorithms\n",
    "    'fit_intercept': [True, False],                 # Whether to include intercept term\n",
    "    'max_iter': [50, 100, 200, 400, 800]            # Maximum iterations for convergence\n",
    "}\n",
    "\n",
    "# Use grid search with cross-validation to find best hyperparameters\n",
    "# This systematically tests all combinations to find the optimal settings\n",
    "\n",
    "\n",
    "# Save the best model and parameter combination\n",
    "winning_parameters = grid.best_params_\n",
    "winning_model = grid.best_estimator_\n",
    "\n",
    "print(f'Best hyperparameters: {winning_parameters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the best model on the testing set\n",
    "\n",
    "# Store the accuracy in the results dictionary\n",
    "results['Optimized Regression'] = accuracy\n",
    "\n",
    "print(f'Testing accuracy of optimized model: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot to compare model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final model\n",
    "\n",
    "With the best hyperparameters identified, we'll train our final model and evaluate its performance on the test set. The confusion matrix will help us understand how well the model performs for each class.\n",
    "\n",
    "### 4.1. Model re-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model with winning hyperparameters on complete training set\n",
    "\n",
    "# Calculate test set accuracy\n",
    "\n",
    "print(f'Final model test set accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display normalized confusion matrix\n",
    "cm = confusion_matrix(testing_df['y'], predictions, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No', 'Yes'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix - Test Set (Normalized)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Save assets\n",
    "\n",
    "#### 4.3.1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the processed data directory exists\n",
    "Path('../data/processed').mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Collect the training and testing datasets into a dictionary\n",
    "datasets = {\n",
    "    'training': training_df,\n",
    "    'testing': testing_df\n",
    "}\n",
    "\n",
    "# Save the datasets to a file for future use\n",
    "with open('../data/processed/datasets.pkl', 'wb') as datasets_file:\n",
    "    pickle.dump(datasets, datasets_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the models directory exists\n",
    "Path('../models/model.pkl').parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the final model\n",
    "with open('../models/model.pkl', 'wb') as output_file:\n",
    "    pickle.dump(winning_model, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
